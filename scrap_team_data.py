# -*- coding: utf-8 -*-
"""Scrap_Team_Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xjKM5L9vfIihknaxh7t4cC1TYl4-8iRz
"""

from urllib.request import urlopen
from bs4 import BeautifulSoup, Comment
import pandas as pd

def collect_team_data(year):
  #fstring
  url = f"https://www.basketball-reference.com/leagues/NBA_{year}.html"

  # collect HTML data
  elem = urlopen(url)
  # create beautiful soup object from HTML
  soup = BeautifulSoup(elem, features = "lxml")
  table = soup.find('div', {'id':"all_team-stats-base"})
  comment = table.find(text=lambda text:isinstance(text, Comment))
  commentsoup = BeautifulSoup(comment , 'lxml')
  th = [i.text for i in commentsoup.find_all("th")][1:25]



  tbody = commentsoup.find("tbody")
  rows = tbody.findAll('tr')
  team_stats = [[td.getText() for td in rows[i].findAll('td')]
            for i in range(len(rows))]
  stats = pd.DataFrame(team_stats, columns = th)
  stats.insert(loc= 1, column='Year', value=year)

  #removes special characters
  stats['Team'] = stats['Team'].str.replace('*', '')


  return stats #dataframe

#try
collect_team_data(2000).head()

def collect_advanced_data(year):
  #fstring
  url = f"https://www.basketball-reference.com/leagues/NBA_{year}.html"

  # collect HTML data
  elem = urlopen(url)
  # create beautiful soup object from HTML
  soup = BeautifulSoup(elem, features = "lxml")
  table = soup.find('div', {'id':"all_misc_stats"})
  comment = table.find(text=lambda text:isinstance(text, Comment))
  commentsoup = BeautifulSoup(comment , 'lxml')
  th = [i.text for i in commentsoup.find_all("th")]
  headings = th[5:21]
  
  for i in range(21, 25):
    temp = th[i]
    temp = "Offensive " + temp 
    headings.append(temp)

  for i in range(25, 29):
    temp = th[i]
    temp = "Defensive " + temp
    headings.append(temp)

  tbody = commentsoup.find("tbody")
  
  
  rows = tbody.findAll('tr') ##len(rows) = number of teams
  team_stats = [[td.getText() for td in rows[i].findAll('td')]
            for i in range(len(rows))]

  for (i) in range(len(team_stats)):
    team_stats[i] = team_stats[i][:24]
  stats = pd.DataFrame(team_stats, columns = headings)
    #removes special characters
  stats['Team'] = stats['Team'].str.replace('*', '')
  return stats #dataframe

df2 = collect_advanced_data(1977)
df2.head()

def collect_both_data(year):
  df1 = collect_team_data(year)
  df2 = collect_advanced_data(year)
  merged_full = pd.merge(left = df1, right = df2, on="Team", how = "outer")
  return merged_full


test = collect_both_data(2014)
test.head()

def collect_all_data(start_year, end_year):
  df_list = []
  for year in range(start_year, end_year + 1):
    df_list.append(collect_both_data(year))
  #dfs = [df.set_index('id') for df in df_list]
  final = pd.concat(df_list)
  final.to_csv("./TeamData.csv")

collect_all_data(1980, 2020)

