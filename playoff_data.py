# -*- coding: utf-8 -*-
"""Playoff_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uzUiTGPoBk9AqdYHO6wbSe8y9Q_so997
"""

from urllib.request import urlopen
from bs4 import BeautifulSoup
import pandas as pd

from random import seed
import random as r
from datetime import datetime

def collect_playoff_data(year):
  url = f"https://www.basketball-reference.com/playoffs/NBA_{year}.html"
  elem = urlopen(url)
  soup = BeautifulSoup(elem, features = "lxml")
  soup = soup.find("div", {"id":"all_all_playoffs"})
  soup = soup.find_all("td")[1:]
  soup = [i.text.replace("\n", "").replace("\xa0", ": ") for i in soup]
  soup = [i for i in soup if "over" in i]
  A = []
  B = []
  Winner = []
  result = []
  for ele in soup:
    index = ele.find("over")
    index2 = ele.find('(')
    A.append(ele[:index - 1])
    B.append(ele[index + 5: index2 - 2 ])  
    result.append(ele[index2:])

  
  df = pd.DataFrame(
    {'Team A': A,
     'Team B': B,
     'Winner': A,
     'Outcome': result
    })
  df.insert(loc= 0, column = "Year", value = year)

  # shuffle data such that team A is not neccesarily the winner
  random.seed(datetime.now())
  for i in range(len(df)):
    if (r.random() <= 0.5):
      temp = df.loc[i, "Team A"]
      df.loc[i, "Team A"] = df.loc[i, "Team B"]
      df.loc[i, "Team B"] = temp    

  return df

df = collect_playoff_data(1980)
df

def collect_all(start_year, end_year):
  dfList = []
  for year in range(start_year, end_year + 1):
    dfList.append(collect_playoff_data(year))
  final = pd.concat(dfList)
  final.to_csv("./PlayoffData.csv")

collect_all(1980, 2020)